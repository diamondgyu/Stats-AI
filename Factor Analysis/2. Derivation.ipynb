{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation of Variance\n",
    "\n",
    "3개의 관측변수(행복도, 기대수명, 병원 방문 횟수) 를 2가지 비관측변수(신체적 건강, 정신적 건강) 으로 추정하는 모델을 설계해 보자. \n",
    "관측변수는 $y_1, y_2, y_3$, 비관측변수는 $F_1, F_2$, unique factor는 $\\epsilon_1,\\epsilon_2,\\epsilon_3$ 라 둔다.\n",
    "\n",
    "식을 $y = \\Lambda\\eta + \\epsilon$ 라 두면\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "Var(y) &= \\mathbb{E}[y^2] - \\mathbb{E}[y]^2 \\\\ &= \\mathbb{E}[y^2] = \\mathbb{E}[ (\\Lambda\\eta + \\epsilon)(\\Lambda\\eta + \\epsilon)^T] \\\\ &= \\mathbb{E}[ (\\Lambda\\eta + \\epsilon)(\\eta^T\\Lambda^T + \\epsilon^T)]  \\\\ &= \\mathbb{E}[\\Lambda\\eta\\eta^T\\Lambda^T + \\Lambda\\eta\\epsilon^T + \\epsilon\\eta^T\\Lambda^T + \\epsilon\\epsilon^T] \\\\ &= \\Lambda\\mathbb{E}[\\eta\\eta^T]\\Lambda^T + \\Lambda\\mathbb{E}[\\eta\\epsilon^T] + \\mathbb{E}[\\epsilon\\eta^T]\\Lambda^T + \\mathbb{E}[\\epsilon\\epsilon^T] \\\\ &= \\Lambda\\mathbb{E}[\\eta\\eta^T]\\Lambda^T + \\mathbb{E}[\\epsilon\\epsilon^T] ~~(\\because \\mathbb{E}[\\eta\\epsilon^T] = 0,~~ \\mathbb{E}[\\epsilon\\eta^T] = 0)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "이때 $\\mathbb{E}[\\eta\\eta^T]$를 $\\Phi$ (F들의 공분산행렬), $\\mathbb{E}[\\epsilon\\epsilon^T]$를 $\\Theta$ 라 하면 식은\n",
    "\n",
    "$\n",
    "Var(y) = \\Lambda\\Phi\\Lambda^T + \\Theta\n",
    "$\n",
    "\n",
    "가 된다.\n",
    "\n",
    "그런데 이 람다는 어떻게 구하는 것일까? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Factor Loading**\n",
    "\n",
    "람다를 구하는 법을 알아보기 전에, 람다의 특성을 먼저 알아보자. 이 람다 값 해는 무한히 많이 존재한다. 그 이유는 간단하게도 변수의 개수보다 식의 개수가 적기 때문이다. 각 속성($y_1, y_2, ...$) 에 대한 람다 값들($\\lambda_1, \\lambda_2, ...$)을 공간상 하나의 점들이라 생각하면, 이 공간의 축을 회전해 새로운 좌표를 얻어도 여전히 유효한 람다 값이 나온다. 이렇기 때문에, 보통 하나의 람다 값을 찾은 뒤 그 값을 회전해 우리의 상식 혹은 가설에 맞는 값들을 도출해내곤 한다.\n",
    "그렇다면 하나의 람다 값을 찾기만 하면 되는데, 그 방법을 알아보자.\n",
    "\n",
    "## **First Factor Solution**\n",
    "\n",
    "보통 최초의 람다를 찾는 데에는 Principal Component Analysis(PCA)를 사용한다. 이전 FA모델을 보면 람다 부분과 엡실론 부분으로 나누어지는데, 이 중 람다 부분(팩터를 통해 설명된 부분) 의 분산을 최대화하는 람다 값을 찾아내는 것이 PCA의 목표이다. \n",
    "\n",
    "PCA는 다음과 같은 절차로 이루어진다:\n",
    "1. 데이터를 정규화한다.\n",
    "2. 데이터의 공분산행렬을 구한다.\n",
    "3. 공분산행렬의 고윳값과 고유벡터를 구한다.\n",
    "4. 고윳값이 높은 순서대로 높은 우선순위의 고유벡터가 된다.\n",
    "\n",
    "* 그런데 왜 고유벡터가 '분산을 최대로 하는' 벡터인 것인가?\n",
    "\n",
    "그건 좀 어렵다..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
